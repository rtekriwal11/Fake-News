{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dependencies for the project\n",
    "import numpy as np      \n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raahiltekriwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk stands for NATURAL LANGUAGE TOOL KIT\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# printing the stopwords in English\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAKE_NEWS DATASET\n",
    "dataset= pd.read_csv('fake-news/train.csv')\n",
    "datasetf=pd.read_csv('fake-news/test.csv')\n",
    "sub=pd.read_csv('fake-news/submit.csv')\n",
    "# Extract the last column from 'sub'\n",
    "label = sub.columns[-1]\n",
    "last_column_sub = sub.pop(label)\n",
    "# Insert the extracted column into 'test'\n",
    "datasetf[label] = last_column_sub\n",
    "Fake_news_dataset = pd.concat([dataset, datasetf], axis=0, sort=False)\n",
    "# counting the number of missing values in the dataset\n",
    "Fake_news_dataset.isnull().sum()\n",
    "# replacing the null values with empty string\n",
    "Fake_news_dataset = Fake_news_dataset.fillna('')\n",
    "# merging the author name and news title\n",
    "Fake_news_dataset['content'] = Fake_news_dataset['author']+' '+Fake_news_dataset['title']\n",
    "Fake_news_dataset.pop('title')\n",
    "Fake_news_dataset.pop('author')\n",
    "Fake_news_dataset.rename(columns={\"content\": \"title\"}, inplace=True)\n",
    "ff=Fake_news_dataset.pop('title')\n",
    "#Fake_news_dataset[1]=ff\n",
    "Fake_news_dataset.insert(1,'title',ff)\n",
    "\n",
    "\n",
    "#Playing with fake or real news\n",
    "fake_real_ds=pd.read_csv('fake_or_real_news.csv')\n",
    "\n",
    "#WELFAKE_DATASET\n",
    "welfake_ds=pd.read_csv('WELFake_Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fake-news-dataset= (26000, 4)\n",
      "Shape of fake or real news dataset= (6335, 4)\n",
      "Shape of welfake dataset= (72134, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of fake-news-dataset=\",Fake_news_dataset.shape)\n",
    "print(\"Shape of fake or real news dataset=\",fake_real_ds.shape)\n",
    "print(\"Shape of welfake dataset=\",welfake_ds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Darrell Lucus House Dem Aide: We Didn’t Even S...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  Darrell Lucus House Dem Aide: We Didn’t Even S...   \n",
       "1   1  Daniel J. Flynn FLYNN: Hillary Clinton, Big Wo...   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_news_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_real_ds.rename(columns={\"unnamed:0\":\"id\"})\n",
    "fake_real_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "welfake_ds.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting multiclass labels to two classes - Fake and True for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_dataset_train = pd.read_csv('liar_dataset/train.csv', delimiter='\\t', quoting=3, header=None)\n",
    "liar_dataset_test = pd.read_csv('liar_dataset/test.csv', delimiter='\\t', quoting=3, header=None)\n",
    "liar_dataset_valid = pd.read_csv('liar_dataset/valid.csv', delimiter='\\t', quoting=3, header=None)\n",
    "df_raw = pd.concat([liar_dataset_train, liar_dataset_test, liar_dataset_valid], axis=0, sort=False)\n",
    "df_raw = df_raw.sample(frac=1).reset_index()\n",
    "# naming the columns of the dataset\n",
    "df_raw.columns=[\"index\",\"ID\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \"state\", \"party\", \"barely_true_cts\",\n",
    "        \"false_cts\", \"half_true_cts\", \"mostly_true_cts\", \"pants_on_fire_cts\", \"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for mapping labels \"true, mostly-true, half-true\" to TRUE and \"false, barely-true, pants-fire\" to FAKE.\n",
    "def binary_class_dataset(data):\n",
    "    data['title'] = data['speaker']+' '+data['subject']+' '+data['context']\n",
    "    data.rename(columns={\"index\":\"id\"},inplace=True)\n",
    "    data = data.iloc[:, [0,2, 3,15]]\n",
    "    #data.insert(1,'title',data_title)\n",
    "    data.columns = ['id','label', 'text', 'title']\n",
    "    data_label=data.pop('label')\n",
    "    data_stmt=data.pop('text')\n",
    "    data_title=data.pop('title')\n",
    "    data.insert(1,'title',data_title)\n",
    "    data.insert(2,'text',data_stmt)\n",
    "    data.insert(3,'label',data_label)\n",
    "    Original_labels = {\n",
    "        'true': 'True',\n",
    "        'mostly-true': 'True',\n",
    "        'half-true': 'True',\n",
    "        'false': 'Fake',\n",
    "        'barely-true': 'Fake',\n",
    "        'pants-fire': 'Fake'\n",
    "    }\n",
    "    data['label'] = data['label'].map(Original_labels)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/__/jb11qx_j05xbp2jtkz0wysww0000gn/T/ipykernel_1574/1605751161.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'].map(Original_labels)\n"
     ]
    }
   ],
   "source": [
    "# running the function on the loaded dataframe\n",
    "bi_class= binary_class_dataset(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1283, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liar_dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12836, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of missing values in the dataset\n",
    "Fake_news_dataset.isnull().sum()\n",
    "fake_real_ds.isnull().sum()\n",
    "welfake_ds.isnull().sum()\n",
    "bi_class.isnull().sum()\n",
    "# replacing the null values with empty string\n",
    "Fake_news_dataset = Fake_news_dataset.fillna('')\n",
    "fake_real_ds = fake_real_ds.fillna('')\n",
    "welfake_ds=welfake_ds.fillna('')\n",
    "bi_class=bi_class.fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing a word to its Root word\n",
    "example: actor, actress, acting --> act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fake_news_dataset['text'] = Fake_news_dataset['text'].apply(stemming)\n",
    "Fake_news_dataset['title'] = Fake_news_dataset['title'].apply(stemming)\n",
    "fake_real_ds['text']=fake_real_ds['text'].apply(stemming)\n",
    "fake_real_ds['title']=fake_real_ds['title'].apply(stemming)\n",
    "welfake_ds['text']=welfake_ds['text'].apply(stemming)\n",
    "welfake_ds['title']=welfake_ds['title'].apply(stemming)\n",
    "bi_class['text']=bi_class['text'].apply(stemming)\n",
    "bi_class['title']=bi_class['title'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26000, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_news_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12836, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_real_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['id', 'title', 'text']\n",
    "unlabeled_data = pd.DataFrame(columns=new_columns)\n",
    "#new_row_data = Fake_news_dataset.iloc[int(0.3 * len(Fake_news_dataset)), :2]\n",
    "unlabeled_data = Fake_news_dataset[['id', 'title', 'text']].iloc[-int(0.7 * len(Fake_news_dataset)):]\n",
    "unlabeled_data=unlabeled_data._append(fake_real_ds.iloc[-int(0.7 * len(fake_real_ds)):, :-1].reset_index(drop=True))\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in unlabeled_data.columns:\n",
    "    unlabeled_data = unlabeled_data.drop('Unnamed: 0', axis=1)\n",
    "#unlabeled_data=unlabeled_data.append(new_row_data,ignore_index=True)\n",
    "#unlabeled_data=unlabeled_data.append(fake_real_ds.iloc[0.5*len(fake_real_ds):,:],ignore_index=True)\n",
    "unlabeled_data=unlabeled_data._append(welfake_ds.iloc[-int(0.7*len(welfake_ds)):,:-1].reset_index(drop=True))\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in unlabeled_data.columns:\n",
    "    unlabeled_data = unlabeled_data.drop('Unnamed: 0', axis=1)\n",
    "unlabeled_data=unlabeled_data._append(bi_class.iloc[-int(0.7*len(bi_class)):,:-1].reset_index(drop=True))\n",
    "unlabeled_data = unlabeled_data.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in unlabeled_data.columns:\n",
    "    unlabeled_data = unlabeled_data.drop('Unnamed: 0', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(unlabeled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82112, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7800.0</td>\n",
       "      <td>nathaniel popper wall st regul propos stricter...</td>\n",
       "      <td>regul releas rule thursday morn aim restrict b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7801.0</td>\n",
       "      <td>luca nolan mark zuckerberg call univers basic ...</td>\n",
       "      <td>facebook ceo mark zuckerberg close commenc spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  7800.0  nathaniel popper wall st regul propos stricter...   \n",
       "1  7801.0  luca nolan mark zuckerberg call univers basic ...   \n",
       "\n",
       "                                                text  \n",
       "0  regul releas rule thursday morn aim restrict b...  \n",
       "1  facebook ceo mark zuckerberg close commenc spe...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           0.0\n",
       "1           1.0\n",
       "2           2.0\n",
       "3           3.0\n",
       "4           4.0\n",
       "          ...  \n",
       "35185     456.0\n",
       "35186    1001.0\n",
       "35187    1353.0\n",
       "35188    7619.0\n",
       "35189     246.0\n",
       "Name: id, Length: 35190, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_Tfid=pd.DataFrame\n",
    "#dataset_Tfid.columns['id','title','text','label']\n",
    "#dataset_Tfid=dataset_Tfid.append(Fake_news_dataset.iloc[:0.3*len(Fake_news_dataset),:],ignore_index=True)\n",
    "#dataset_Tfid=dataset_Tfid.append(fake_real_ds.iloc[:0.5*len(fake_real_ds),:],ignore_index=True)\n",
    "#dataset_Tfid=dataset_Tfid.append(welfake_ds.iloc[:0.3*len(welfake_ds),:],ignore_index=True)\n",
    "#dataset_Tfid=dataset_Tfid.append(bi_class.iloc[:0.3*len(bi_class),:],ignore_index=True)\n",
    "\n",
    "\n",
    "column = ['id', 'title', 'text','label']\n",
    "dataset_Tfid = pd.DataFrame(columns=column)\n",
    "#new_row_data = Fake_news_dataset.iloc[int(0.3 * len(Fake_news_dataset)), :2]\n",
    "dataset_Tfid = Fake_news_dataset[['id', 'title', 'text','label']].iloc[:int(0.3 * len(Fake_news_dataset)):]\n",
    "dataset_Tfid=dataset_Tfid._append(fake_real_ds.iloc[:int(0.3 * len(fake_real_ds)):, :].reset_index(drop=True))\n",
    "dataset_Tfid = dataset_Tfid.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in dataset_Tfid.columns:\n",
    "    dataset_Tfid = dataset_Tfid.drop('Unnamed: 0', axis=1)\n",
    "dataset_Tfid=dataset_Tfid._append(welfake_ds.iloc[:int(0.3*len(welfake_ds)):,:].reset_index(drop=True))\n",
    "dataset_Tfid = dataset_Tfid.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in dataset_Tfid.columns:\n",
    "    dataset_Tfid = dataset_Tfid.drop('Unnamed: 0', axis=1)\n",
    "dataset_Tfid=dataset_Tfid._append(bi_class.iloc[:int(0.3*len(bi_class)):,:].reset_index(drop=True))\n",
    "dataset_Tfid = dataset_Tfid.reset_index(drop=True)\n",
    "if 'Unnamed: 0' in dataset_Tfid.columns:\n",
    "    dataset_Tfid = dataset_Tfid.drop('Unnamed: 0', axis=1)\n",
    "col=['label']\n",
    "Y=pd.DataFrame(columns=col)\n",
    "#Y=dataset_Tfid.pop('label')\n",
    "dataset_Tfid.pop('id')\n",
    "\n",
    "\n",
    "#dataset_Tfid=Fake_news_dataset.iloc[:,[0,1,2]]\n",
    "# converting the textual data to numerical data\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vectorizer.fit(dataset_Tfid)\n",
    "\n",
    "#dataset_Tfid = vectorizer.transform(dataset_Tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35190, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Tfid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrel lucu hous dem aid even see comey letter...</td>\n",
       "      <td>hous dem aid even see comey letter jason chaff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daniel j flynn flynn hillari clinton big woman...</td>\n",
       "      <td>ever get feel life circl roundabout rather hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>consortiumnew com truth might get fire</td>\n",
       "      <td>truth might get fire octob tension intellig an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jessica purkiss civilian kill singl us airstri...</td>\n",
       "      <td>video civilian kill singl us airstrik identifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>howard portnoy iranian woman jail fiction unpu...</td>\n",
       "      <td>print iranian woman sentenc six year prison ir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  darrel lucu hous dem aid even see comey letter...   \n",
       "1  daniel j flynn flynn hillari clinton big woman...   \n",
       "2             consortiumnew com truth might get fire   \n",
       "3  jessica purkiss civilian kill singl us airstri...   \n",
       "4  howard portnoy iranian woman jail fiction unpu...   \n",
       "\n",
       "                                                text label  \n",
       "0  hous dem aid even see comey letter jason chaff...     1  \n",
       "1  ever get feel life circl roundabout rather hea...     0  \n",
       "2  truth might get fire octob tension intellig an...     1  \n",
       "3  video civilian kill singl us airstrik identifi...     1  \n",
       "4  print iranian woman sentenc six year prison ir...     1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Tfid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_Tfid['label'] = dataset_Tfid['label'].replace({'FAKE': 1, 'TRUE': 0, 'Fake':1, 'Real':0, 'True':0, 'REAL': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with string values in the 'label' column: 0\n",
      "\n",
      "Rows with string values:\n",
      "Empty DataFrame\n",
      "Columns: [title, text, label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Check and print rows where the 'label' column contains string values\n",
    "column_name = 'label'  # Replace with the actual column name in your DataFrame\n",
    "\n",
    "# Filter rows with string values in the 'label' column\n",
    "string_rows = dataset_Tfid[dataset_Tfid[column_name].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Count the number of rows with string values\n",
    "count_string_rows = len(string_rows)\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of rows with string values in the '{column_name}' column: {count_string_rows}\")\n",
    "\n",
    "# Print the rows\n",
    "print(\"\\nRows with string values:\")\n",
    "print(string_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=dataset_Tfid.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35190, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=['content']\n",
    "dataset_Tfid_content=pd.DataFrame(columns=col)\n",
    "dataset_Tfid_content['content']=dataset_Tfid['title']+' '+dataset_Tfid['text']\n",
    "dataset_Tfid_content.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35190, 108627)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X=dataset_Tfid_content['content'].values\n",
    "vectorizer.fit(X)\n",
    "X_label = vectorizer.transform(X)\n",
    "X_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82112, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=['content']\n",
    "unlabeled_data_title=pd.DataFrame(columns=col)\n",
    "unlabeled_data_title['content']=unlabeled_data['title']+' '+unlabeled_data['text']\n",
    "unlabeled_data_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the textual data to numerical data\n",
    "vectorizer1 = TfidfVectorizer()\n",
    "Z=unlabeled_data_title['content'].values\n",
    "vectorizer1.fit(Z)\n",
    "X_unlabel = vectorizer1.transform(Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82112, 159011)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([dataset_Tfid_content['content'], unlabeled_data_title['content']], axis=0)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_combined = vectorizer.fit_transform(combined_data)\n",
    "\n",
    "X_labeled = vectorizer.transform(dataset_Tfid_content['content'])\n",
    "X_unlabeled = vectorizer.transform(unlabeled_data_title['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_value=Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 170985)\t0.05245377570557459\n",
      "  (0, 170894)\t0.020328659384524096\n",
      "  (0, 168822)\t0.04673577771364503\n",
      "  (0, 168816)\t0.0956702121867596\n",
      "  (0, 168749)\t0.042027721417381966\n",
      "  (0, 168697)\t0.012359299055411074\n",
      "  (0, 167585)\t0.01715251239728547\n",
      "  (0, 166341)\t0.017955875123165627\n",
      "  (0, 166206)\t0.013583619011229712\n",
      "  (0, 166089)\t0.031128629357328262\n",
      "  (0, 165956)\t0.013309998278248181\n",
      "  (0, 165588)\t0.012889180937954636\n",
      "  (0, 164141)\t0.025296211984276853\n",
      "  (0, 164076)\t0.03017286750063937\n",
      "  (0, 162610)\t0.017023237944112767\n",
      "  (0, 160473)\t0.06325933309983671\n",
      "  (0, 159443)\t0.03389216895591256\n",
      "  (0, 159116)\t0.017993446698815863\n",
      "  (0, 158159)\t0.0392000825046848\n",
      "  (0, 157009)\t0.011920998436672063\n",
      "  (0, 156835)\t0.0471151224820326\n",
      "  (0, 156741)\t0.12493332180520851\n",
      "  (0, 156499)\t0.07805222531207115\n",
      "  (0, 154418)\t0.03999893701201339\n",
      "  (0, 153568)\t0.02765455620535052\n",
      "  :\t:\n",
      "  (35188, 119700)\t0.1538423422307\n",
      "  (35188, 114674)\t0.09140722092623646\n",
      "  (35188, 94754)\t0.14833985354906232\n",
      "  (35188, 88469)\t0.12425431689275337\n",
      "  (35188, 84956)\t0.13248520561517516\n",
      "  (35188, 74342)\t0.26886743923212586\n",
      "  (35188, 35312)\t0.17245504797696307\n",
      "  (35188, 31198)\t0.2083352707937456\n",
      "  (35188, 30084)\t0.1610648589826851\n",
      "  (35188, 29341)\t0.14046899628454754\n",
      "  (35188, 29183)\t0.22166558556311985\n",
      "  (35188, 22660)\t0.14448980979270748\n",
      "  (35188, 21373)\t0.19572263633458342\n",
      "  (35188, 16301)\t0.2813441598713368\n",
      "  (35188, 16081)\t0.15201453921114727\n",
      "  (35188, 13731)\t0.1804401767942743\n",
      "  (35189, 165775)\t0.3459748560439446\n",
      "  (35189, 144037)\t0.1289463002592423\n",
      "  (35189, 96248)\t0.27830279640458466\n",
      "  (35189, 84956)\t0.19413916693860672\n",
      "  (35189, 71561)\t0.21214433236882396\n",
      "  (35189, 60802)\t0.5772904246081291\n",
      "  (35189, 56190)\t0.37558446849884436\n",
      "  (35189, 32305)\t0.26114581886890825\n",
      "  (35189, 17305)\t0.40124992737429505\n"
     ]
    }
   ],
   "source": [
    "print(X_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82112, 174402)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_unlabeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after self-training on 1st set: 0.8938618925831202\n",
      "Accuracy after self-training on 2nd set: 0.8913043478260869\n",
      "Accuracy after self-training on 3rd set: 0.8891730605285593\n",
      "Recall after self-training on 1st set: 0.8959731543624161\n",
      "Recall after self-training on 2nd set: 0.9117896522476675\n",
      "Recall after self-training on 3rd set: 0.9051217464315701\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import recall_score\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_labeled, Y_value, test_size = 0.2, stratify=Y, random_state=2)\n",
    "\n",
    "#num_rows_half = X_test.shape[0] // 2\n",
    "\n",
    "#X1_test,X2_test=X_test[:num_rows_half,:],X_test[num_rows_half:,:]\n",
    "#Y1_test,Y2_test=Y_test[:num_rows_half],Y_test[num_rows_half:]\n",
    "\n",
    "num_rows_third = X_unlabeled.shape[0] // 3\n",
    "\n",
    "# Split the CSR matrix into three sets\n",
    "X1_unlabeled = X_unlabeled[:num_rows_third, :]\n",
    "X2_unlabeled = X_unlabeled[num_rows_third: 2 * num_rows_third, :]\n",
    "X3_unlabeled = X_unlabeled[2 * num_rows_third:, :]\n",
    "\n",
    "num_rows_test=X_test.shape[0]//3\n",
    "X1_test,X2_test,X3_test=X_test[:num_rows_test,:],X_test[num_rows_test: 2*num_rows_test,:],X_test[2*num_rows_test:,:]\n",
    "Y1_test,Y2_test,Y3_test=Y_test[:num_rows_test],Y_test[num_rows_test: 2*num_rows_test],Y_test[2*num_rows_test:]\n",
    "\n",
    "\n",
    "# Train an initial model on the labeled data\n",
    "model1 = LogisticRegression(max_iter=1000)\n",
    "model1.fit(X_train, Y_train)\n",
    "\n",
    "# Use the trained model to predict on unlabeled data\n",
    "pseudo_labels_1 = model1.predict(X1_unlabeled)\n",
    "\n",
    "# Combine labeled and pseudo-labeled data\n",
    "X1_combined=vstack([X_train, X1_unlabeled])\n",
    "y1_combined = np.concatenate([Y_train, pseudo_labels_1])\n",
    "\n",
    "# Retrain the model on the combined data\n",
    "model1.fit(X1_combined, y1_combined)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y1_pred = model1.predict(X1_test)\n",
    "accuracy_1 = accuracy_score(Y1_test, y1_pred)\n",
    "print(f\"Accuracy after self-training on 1st set: {accuracy_1}\")\n",
    "\n",
    "# Repeat for second half of unlabeled data\n",
    "pseudo_labels_2 = model1.predict(X2_unlabeled)\n",
    "\n",
    "# Combine labeled and pseudo-labeled data\n",
    "X2_combined=vstack([X1_combined, X2_unlabeled])\n",
    "y2_combined = np.concatenate([y1_combined, pseudo_labels_2])\n",
    "\n",
    "# Retrain the model on the combined data\n",
    "model1.fit(X2_combined, y2_combined)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y2_pred = model1.predict(X2_test)\n",
    "accuracy_2 = accuracy_score(Y2_test, y2_pred)\n",
    "print(f\"Accuracy after self-training on 2nd set: {accuracy_2}\")\n",
    "\n",
    "\n",
    "# Repeat for second half of unlabeled data\n",
    "pseudo_labels_3 = model1.predict(X3_unlabeled)\n",
    "\n",
    "# Combine labeled and pseudo-labeled data\n",
    "X3_combined=vstack([X2_combined, X3_unlabeled])\n",
    "y3_combined = np.concatenate([y2_combined, pseudo_labels_3])\n",
    "\n",
    "# Retrain the model on the combined data\n",
    "model1.fit(X3_combined, y3_combined)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "y3_pred = model1.predict(X3_test)\n",
    "accuracy_3 = accuracy_score(Y3_test, y3_pred)\n",
    "print(f\"Accuracy after self-training on 3rd set: {accuracy_3}\")\n",
    "\n",
    "recall_1 = recall_score(Y1_test, y1_pred)\n",
    "print(f\"Recall after self-training on 1st set: {recall_1}\")\n",
    "\n",
    "# Calculate recall for the 2nd set\n",
    "recall_2 = recall_score(Y2_test, y2_pred)\n",
    "print(f\"Recall after self-training on 2nd set: {recall_2}\")\n",
    "\n",
    "# Calculate recall for the 3rd set\n",
    "recall_3 = recall_score(Y3_test, y3_pred)\n",
    "print(f\"Recall after self-training on 3rd set: {recall_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the test data :  0.8962773515203183\n",
      "Recall on the test data: 0.9084783829309376\n"
     ]
    }
   ],
   "source": [
    "X_train_supervised, X_test_supervised, Y_train_supervised, Y_test_supervised = train_test_split(X_labeled, Y_value, test_size = 0.2, stratify=Y, random_state=2)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_supervised, Y_train_supervised)\n",
    "# accuracy score on the training data\n",
    "#X_train_prediction = model.predict(X_train)\n",
    "#training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "# accuracy score on the test data\n",
    "X_test_prediction = model.predict(X_test_supervised)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test_supervised)\n",
    "print('Accuracy score of the test data : ', test_data_accuracy)\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall for the test data\n",
    "recall_test = recall_score(Y_test_supervised, X_test_prediction)\n",
    "print(f\"Recall on the test data: {recall_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
